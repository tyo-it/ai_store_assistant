<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>OpenAI Realtime Voice Assistant</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
      background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      color: #333;
    }

    .container {
      background: white;
      border-radius: 24px;
      padding: 2.5rem;
      box-shadow: 0 25px 50px rgba(0, 0, 0, 0.15);
      max-width: 700px;
      width: 95%;
    }

    .header {
      text-align: center;
      margin-bottom: 2rem;
    }

    .header h1 {
      color: #2a5298;
      margin-bottom: 0.5rem;
      font-size: 2rem;
    }

    .header p {
      color: #666;
      font-size: 1.1rem;
    }

    .status-badge {
      display: inline-block;
      padding: 0.5rem 1rem;
      border-radius: 20px;
      font-size: 0.9rem;
      margin-top: 1rem;
      font-weight: 500;
    }

    .status-badge.connected {
      background: #d4edda;
      color: #155724;
      border: 1px solid #c3e6cb;
    }

    .status-badge.connecting {
      background: #fff3cd;
      color: #856404;
      border: 1px solid #ffeaa7;
    }

    .status-badge.error {
      background: #f8d7da;
      color: #721c24;
      border: 1px solid #f5c6cb;
    }

    .chat-container {
      height: 350px;
      overflow-y: auto;
      border: 2px solid #e9ecef;
      border-radius: 16px;
      padding: 1.5rem;
      margin-bottom: 1.5rem;
      background: #f8f9fa;
    }

    .message {
      margin-bottom: 1rem;
      padding: 1rem 1.5rem;
      border-radius: 18px;
      max-width: 85%;
      word-wrap: break-word;
    }

    .message.user {
      background: #2a5298;
      color: white;
      margin-left: auto;
    }

    .message.assistant {
      background: white;
      color: #333;
      border: 1px solid #dee2e6;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }

    .message.transcript {
      background: #e3f2fd;
      color: #1565c0;
      font-style: italic;
      border-left: 4px solid #2196f3;
      margin-left: auto;
    }

    .controls {
      display: flex;
      flex-direction: column;
      gap: 1rem;
      margin-bottom: 1.5rem;
    }

    .voice-controls {
      display: flex;
      gap: 1rem;
      align-items: center;
    }

    .voice-button {
      background: #28a745;
      color: white;
      border: none;
      padding: 1.2rem 2rem;
      border-radius: 50px;
      cursor: pointer;
      font-size: 1.1rem;
      font-weight: 600;
      transition: all 0.3s ease;
      flex: 1;
      position: relative;
    }

    .voice-button:hover:not(:disabled) {
      background: #218838;
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(40, 167, 69, 0.4);
    }

    .voice-button:disabled {
      background: #6c757d;
      cursor: not-allowed;
    }

    .voice-button.listening {
      background: #dc3545;
      animation: pulse 1.5s infinite;
    }

    @keyframes pulse {
      0% {
        transform: scale(1);
        box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7);
      }

      70% {
        transform: scale(1.05);
        box-shadow: 0 0 0 10px rgba(220, 53, 69, 0);
      }

      100% {
        transform: scale(1);
        box-shadow: 0 0 0 0 rgba(220, 53, 69, 0);
      }
    }

    body {
      font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
      padding: 0.5rem;
      background: white;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      color: #333;
    }

    .container {
      background: white;
      border-radius: 24px;
      padding: 1.0rem;
      box-shadow: 0 25px 50px rgba(0, 0, 0, 0.15);
      max-width: 700px;
      width: 95%;
    }

    .interrupt-button {
      background: #6c757d;
      color: white;
      border: none;
      padding: 0.8rem 1.5rem;
      border-radius: 25px;
      cursor: pointer;
      font-size: 0.9rem;
      transition: background 0.3s;
    }

    .interrupt-button:hover:not(:disabled) {
      background: #5a6268;
    }

    .interrupt-button:disabled {
      background: #adb5bd;
      cursor: not-allowed;
    }

    .header p {
      color: #666;
      font-size: 0.6rem;
    }

    .settings {
      display: flex;
      gap: 1rem;
      align-items: center;
      flex-wrap: wrap;
    }

    .voice-select {
      padding: 0.7rem 1rem;
      border: 2px solid #e9ecef;
      border-radius: 20px;
      font-size: 0.9rem;
      outline: none;
      background: white;
    }

    .voice-select:focus {
      border-color: #2a5298;
    }

    .voice-select:disabled {
      background: #f8f9fa;
      cursor: not-allowed;
    }

    .chat-container {
      height: 350px;
      overflow-y: auto;
      border: 2px solid #e9ecef;
      border-radius: 16px;
      padding: 1.0rem;
      margin-bottom: 1.5rem;
      background: #f8f9fa;
    }

    .text-input {
      display: flex;
      gap: 0.5rem;
    }

    .text-input input {
      flex: 1;
      padding: 1rem 1.5rem;
      border: 2px solid #e9ecef;
      border-radius: 25px;
      outline: none;
      font-size: 1rem;
    }

    .text-input input:focus {
      border-color: #2a5298;
    }

    .text-input input:disabled {
      background: #f8f9fa;
      cursor: not-allowed;
    }

    .text-input button {
      background: #2a5298;
      color: white;
      border: none;
      padding: 1rem 2rem;
      border-radius: 25px;
      cursor: pointer;
      font-size: 1rem;
      font-weight: 600;
      transition: background 0.3s;
    }

    .text-input button:hover:not(:disabled) {
      background: #1e3c72;
    }

    .text-input button:disabled {
      background: #6c757d;
      cursor: not-allowed;
    }

    .confirmation-buttons {
      background: #fff3cd;
      border: 2px solid #ffeaa7;
      border-radius: 16px;
      padding: 1.5rem;
      margin: 1rem 0;
      text-align: center;
    }

    .confirmation-message {
      color: #856404;
      font-weight: 500;
      margin-bottom: 1rem;
      font-size: 1rem;
    }

    .button-group {
      display: flex;
      gap: 1rem;
      justify-content: center;
    }

    .confirm-btn {
      padding: 0.75rem 1.5rem;
      border: none;
      border-radius: 12px;
      font-size: 1rem;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.3s ease;
      min-width: 120px;
    }

    .confirm-btn.yes {
      background: #28a745;
      color: white;
    }

    .confirm-btn.yes:hover {
      background: #218838;
      transform: translateY(-2px);
    }

    .confirm-btn.no {
      background: #dc3545;
      color: white;
    }

    .confirm-btn.no:hover {
      background: #c82333;
      transform: translateY(-2px);
    }

    .status {
      text-align: center;
      padding: 1rem;
      font-size: 0.95rem;
      color: #666;
      background: #f8f9fa;
      border-radius: 12px;
      margin-top: 1rem;
    }

    .features {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1rem;
      margin-top: 2rem;
      padding: 1.5rem;
      background: #f8f9fa;
      border-radius: 16px;
    }

    .feature {
      text-align: center;
      padding: 1rem;
    }

    .feature-icon {
      font-size: 2rem;
      margin-bottom: 0.5rem;
    }

    .feature h3 {
      color: #2a5298;
      margin-bottom: 0.5rem;
      font-size: 1rem;
    }

    .feature p {
      color: #666;
      font-size: 0.9rem;
    }



    .text-input input {
      flex: 1;
      padding: 0.5rem 1.0rem;
      border: 2px solid #e9ecef;
      border-radius: 25px;
      outline: none;
      font-size: 1rem;
    }

    /* Modal for custom stop dialog */
    .modal-overlay {
      position: fixed;
      inset: 0;
      background: rgba(0, 0, 0, 0.5);
      display: none;
      justify-content: center;
      align-items: center;
      padding: 1rem;
      z-index: 9999;
    }

    .modal {
      background: #ffffff;
      border-radius: 16px;
      width: 100%;
      max-width: 420px;
      padding: 1.5rem;
      box-shadow: 0 20px 40px rgba(0, 0, 0, 0.2);
      text-align: center;
    }

    .modal h3 {
      color: #2a5298;
      font-size: 1.25rem;
      margin-bottom: 0.5rem;
    }

    .modal p {
      color: #666;
      margin-bottom: 1rem;
      font-size: 0.95rem;
    }

    .qr-code {
      display: block;
      margin: 0.5rem auto 1rem;
      width: 200px;
      height: 200px;
      border-radius: 12px;
      background: #f8f9fa;
      padding: 0.5rem;
      border: 1px solid #e9ecef;
    }

    /* Canvas target for generated QR */
    #qr-code {
      display: block;
      margin: 0.5rem auto 1rem;
      width: 200px;
      height: 200px;
      background: #f8f9fa;
      border: 1px solid #e9ecef;
      border-radius: 12px;
    }

    .modal-actions {
      display: flex;
      justify-content: center;
      gap: 0.75rem;
      margin-top: 0.5rem;
    }

    .feature p {
      color: #666;
      font-size: 0.9rem;
    }

    /* Logo styling */
    .logo {
      display: flex;
      margin: 0 auto;
      max-width: 200px;
      height: auto;
    }
  </style>
</head>

<body>
  <div class="container">

    <div class="header">
      <img src="./assets/logo.png" alt="FAZZRIE logo" class="logo" />
      <div class="status-badge connecting" id="connectionStatus">
        Connecting...
      </div>
    </div>

    <div class="chat-container" id="chatContainer">
      <div class="message assistant">
        <strong>FAZZRIE:</strong>
        <span class="message-content">Halo! Ada yang bisa saya bantu
        </span>
      </div>
    </div>

    <div class="controls">
      <div class="voice-controls">
        <button class="voice-button" id="voiceButton" disabled>
          üó£Ô∏è Bicara
        </button>
        <!-- <button class="interrupt-button" id="interruptButton" disabled>
          Berhenti
        </button> -->
      </div>
    </div>

    <div class="text-input">
      <input type="text" id="textInput" placeholder="Tulis pesan disini..." disabled />
      <button id="sendButton" disabled>Kirim</button>
    </div>

    <br />

    <!-- <div class="settings">
      <select class="voice-select" id="voiceSelect" disabled>
        <option value="alloy">Alloy</option>
        <option value="ash">Ash</option>
        <option value="ballad">Ballad</option>
        <option value="coral">Coral</option>
        <option value="echo">Echo</option>
        <option value="sage">Sage</option>
        <option value="shimmer">Shimmer</option>
        <option value="verse">Verse</option>
        <option value="marin">Marin</option>
        <option value="cedar">Cedar</option>
      </select>
    </div> -->

    <!-- Pulsa Confirmation Buttons -->
    <div class="confirmation-buttons" id="confirmationButtons" style="display: none">
      <p class="confirmation-message" id="confirmationMessage"></p>
      <div class="button-group">
        <button id="confirmYes" class="confirm-btn yes">Ya, Lanjutkan</button>
        <button id="confirmNo" class="confirm-btn no">Batal</button>
      </div>
    </div>

    <!-- Custom Stop Modal with QR Code -->
    <div id="stopDialog" class="modal-overlay" style="display: none">
      <div class="modal" role="dialog" aria-modal="true" aria-labelledby="stopDialogTitle">
        <p>Pindai QR untuk untuk melakukan pembayaran.</p>
        <canvas id="qr-code"></canvas>
        <div class="modal-actions">
          <button id="stopCancel" class="confirm-btn yes">Tutup</button>
        </div>
      </div>
    </div>

    <div class="status" id="status">Connecting to OpenAI Realtime API...</div>

    <script src="/socket.io/socket.io.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/qrcode/build/qrcode.min.js"></script>
    <script>
      class RealtimeVoiceClient {
        constructor() {
          this.socket = io();
          this.isRecording = false;
          this.isConnected = false;
          this.mediaRecorder = null;
          this.audioContext = null;
          this.currentAudio = null;
          this.mode = "unknown"; // 'realtime' or 'fallback'
          this.speechRecognition = null;
          this.speechSynthesis = window.speechSynthesis;

          // Speech settings (will be updated from server)
          this.speechRate = 1.0; // Default fallback - slower speech
          this.speechPitch = 1.0; // Default fallback

          // Audio queue management for realtime streaming
          this.audioQueue = [];
          this.isPlayingQueue = false;
          this.nextStartTime = 0;

          this.initializeElements();
          this.setupEventListeners();
          this.setupSocketHandlers();
          this.initializeSpeechRecognition();
        }
        initializeElements() {
          this.chatContainer = document.getElementById("chatContainer");
          this.voiceButton = document.getElementById("voiceButton");
          // this.interruptButton = document.getElementById("interruptButton");
          // this.voiceSelect = document.getElementById("voiceSelect");
          this.textInput = document.getElementById("textInput");
          this.sendButton = document.getElementById("sendButton");
          this.status = document.getElementById("status");
          this.connectionStatus = document.getElementById("connectionStatus");
        }

        setupEventListeners() {
          // Voice button (hold to talk)
          this.voiceButton.addEventListener("mousedown", () =>
            this.startRecording()
          );
          this.voiceButton.addEventListener("mouseup", () =>
            this.stopRecording()
          );
          this.voiceButton.addEventListener("mouseleave", () =>
            this.stopRecording()
          );

          // Touch events for mobile
          this.voiceButton.addEventListener("touchstart", (e) => {
            e.preventDefault();
            this.startRecording();
          });
          this.voiceButton.addEventListener("touchend", (e) => {
            e.preventDefault();
            this.stopRecording();
          });

          // Interrupt button
          // this.interruptButton.addEventListener("click", () =>
          //   this.interrupt()
          // );

          // Voice selection
          // this.voiceSelect.addEventListener("change", (e) => {
          //   // Interrupt any ongoing audio before changing voice
          //   console.log(`üéôÔ∏è Changing voice to: ${e.target.value}`);
          //   this.interrupt(); // Clear any playing audio on client side
          //   this.socket.emit("change-voice", e.target.value);
          // });

          // Text input
          this.sendButton.addEventListener("click", () =>
            this.sendTextMessage()
          );
          this.textInput.addEventListener("keypress", (e) => {
            if (e.key === "Enter") this.sendTextMessage();
          });

          // Confirmation buttons
          document
            .getElementById("confirmYes")
            .addEventListener("click", () => {
              this.handleConfirmation(true);
            });
          document.getElementById("confirmNo").addEventListener("click", () => {
            this.handleConfirmation(false);
          });

          // Stop modal dialog events
          const stopOverlay = document.getElementById("stopDialog");
          const stopConfirm = document.getElementById("stopConfirm");
          const stopCancel = document.getElementById("stopCancel");
          if (stopConfirm) {
            stopConfirm.addEventListener("click", () => {
              this.interrupt();
              if (stopOverlay) stopOverlay.style.display = "none";
            });
          }
          if (stopCancel) {
            stopCancel.addEventListener("click", () => {
              if (stopOverlay) stopOverlay.style.display = "none";
            });
          }
          if (stopOverlay) {
            stopOverlay.addEventListener("click", (e) => {
              if (e.target === stopOverlay) {
                stopOverlay.style.display = "none";
              }
            });
          }
        }

        setupSocketHandlers() {
          this.socket.on("connect", () => {
            console.log("Connected to server");
          });

          this.socket.on("status", (data) => {
            if (data.connected) {
              this.isConnected = true;
              this.mode = data.mode || "unknown";

              // Store speech settings from server
              this.speechRate = data.speechRate || 1.0;
              this.speechPitch = data.speechPitch || 1.0;
              console.log(
                `üé§ Speech settings received from server: rate=${this.speechRate}, pitch=${this.speechPitch}, mode=${this.mode}`
              );

              if (this.mode === "fallback") {
                this.updateConnectionStatus(
                  "connected",
                  "Fallback Mode - Browser Speech"
                );
                this.updateStatus(
                  `Ready! Using browser speech`
                );
              } else {
                this.updateConnectionStatus(
                  "connected",
                  "Connected"
                );
                this.updateStatus(
                  `Ready!`
                );
              }

              this.enableControls();
            } else {
              this.updateStatus(data.message || "Status update received");
            }
          });
          this.socket.on("audio-response", (data) => {
            if (data.type === "audio-delta" && data.audio) {
              this.playAudioDelta(data.audio);
            } else if (data.type === "audio-complete" && data.audio) {
              // Handle server-side TTS audio response
              this.playServerAudio(data.audio, data.text);
            } else if (data.type === "audio-fallback" && data.text) {
              // Fallback to browser TTS if server TTS failed
              console.log("Server TTS failed, using browser TTS");
              this.speakText(data.text);
            }
          });

          this.socket.on("text-response", (data) => {
            if (data.type === "text-delta" && data.text) {
              this.appendToLastMessage("assistant", data.text);
            } else if (data.type === "text-complete" && data.text) {
              this.displayMessage("assistant", data.text);

              // Check if this response needs confirmation (for pulsa purchases)
              if (
                data.needsConfirmation ||
                (data.response && data.response.needsConfirmation)
              ) {
                this.showConfirmationButtons(
                  data.text,
                  data.confirmationData || data.response.confirmationData
                );
              }

              // In fallback mode, the server now handles TTS through audio-response events
              // So we don't need to call speakText here anymore - it will be handled
              // by the audio-response handler with improved server-side TTS
              console.log(
                "Text response received - audio will be handled by server TTS"
              );
            }
          });

          this.socket.on("response-complete", (data) => {
            this.updateStatus("Response complete. Ready for next input.");
          });

          this.socket.on("speech-status", (data) => {
            if (data.type === "speech-started") {
              this.updateStatus("üéôÔ∏è Listening...");
            } else if (data.type === "speech-stopped") {
              this.updateStatus("ü§î Processing...");
            }
          });

          this.socket.on("transcription", (data) => {
            if (data.text) {
              this.displayMessage("transcript", `You said: "${data.text}"`);
            }
          });

          this.socket.on("pending-purchase", (data) => {
            console.log("pending-purchase", data);

            const overlay = document.getElementById("stopDialog");
            if (overlay) overlay.style.display = "flex";

            var url = 'https://chat.clydev.com/payment/' + data.uniqueId;
            const canvas = document.getElementById("qr-code");
            try {
              QRCode.toCanvas(
                canvas,
                url,
                {
                  width: 200,
                  margin: 1,
                  errorCorrectionLevel: "M",
                  color: { dark: "#000000", light: "#ffffff" }
                },
                (err) => {
                  if (err) {
                    console.error("QR generation error:", err);
                  }
                }
              );
            } catch (e) {
              console.error("Failed to render QR to canvas:", e);
            }
          })

          this.socket.on("error", (error) => {
            console.error("Socket error:", error);
            // this.updateConnectionStatus("error", "Error: " + error);
            // this.updateStatus("Error: " + error);
          });

          this.socket.on("disconnect", () => {
            this.isConnected = false;
            this.updateConnectionStatus("connecting", "Disconnected");
            this.disableControls();
          });
        }

        async startRecording() {
          if (!this.isConnected || this.isRecording) return;

          // Clear any existing audio queue before starting new recording
          this.clearAudioQueue();

          if (this.mode === "fallback") {
            // Use browser speech recognition for fallback mode
            if (this.speechRecognition) {
              this.speechRecognition.start();
              this.isRecording = true;
              this.voiceButton.textContent = "üé§ Listening...";
              this.voiceButton.classList.add("listening");
              this.updateStatus("üé§ Speak now...");
            } else {
              this.updateStatus(
                "Speech recognition not supported in this browser"
              );
            }
            return;
          }

          try {
            const stream = await navigator.mediaDevices.getUserMedia({
              audio: {
                sampleRate: 24000,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true,
              },
            });

            // Use separate AudioContext for recording to avoid conflicts with playback
            this.recordingAudioContext = new AudioContext({
              sampleRate: 24000,
            });
            const source =
              this.recordingAudioContext.createMediaStreamSource(stream);

            // Create a script processor for real-time audio data
            const processor = this.recordingAudioContext.createScriptProcessor(
              4096,
              1,
              1
            );
            source.connect(processor);
            processor.connect(this.recordingAudioContext.destination);

            processor.onaudioprocess = (event) => {
              if (this.isRecording) {
                const audioData = event.inputBuffer.getChannelData(0);
                const pcm16Data = this.convertToPCM16(audioData);
                const base64Audio = this.arrayBufferToBase64(pcm16Data);
                this.socket.emit("audio-stream", base64Audio);
              }
            };

            this.mediaStream = stream;
            this.processor = processor;
            this.isRecording = true;

            this.voiceButton.textContent = "üéôÔ∏è Recording...";
            this.voiceButton.classList.add("listening");
            this.updateStatus("üéôÔ∏è Hold button and speak...");
          } catch (error) {
            console.error("Error starting recording:", error);
            this.updateStatus(
              "Error accessing microphone. Please check permissions."
            );
          }
        }

        stopRecording() {
          if (!this.isRecording) return;

          this.isRecording = false;

          // Handle fallback mode with speech recognition
          if (this.mode === "fallback" && this.speechRecognition) {
            this.speechRecognition.stop();
          } else {
            // Handle Realtime API mode
            if (this.mediaStream) {
              this.mediaStream.getTracks().forEach((track) => track.stop());
            }

            if (this.processor) {
              this.processor.disconnect();
            }

            if (this.recordingAudioContext) {
              this.recordingAudioContext.close();
            }

            this.socket.emit("audio-stream-end");
          }

          this.voiceButton.textContent = "üó£Ô∏è Bicara";
          this.voiceButton.classList.remove("listening");
          this.updateStatus("Processing your message...");
        }

        convertToPCM16(audioData) {
          const pcm16 = new Int16Array(audioData.length);
          for (let i = 0; i < audioData.length; i++) {
            pcm16[i] = Math.max(-32768, Math.min(32767, audioData[i] * 32768));
          }
          // Convert to Uint8Array for browser compatibility
          return new Uint8Array(pcm16.buffer);
        }

        arrayBufferToBase64(buffer) {
          let binary = "";
          const bytes = new Uint8Array(buffer);
          const len = bytes.byteLength;
          for (let i = 0; i < len; i++) {
            binary += String.fromCharCode(bytes[i]);
          }
          return window.btoa(binary);
        }

        interrupt() {
          // Stop current audio
          if (this.currentAudio) {
            this.currentAudio.stop();
            this.currentAudio = null;
          }

          // Clear audio queue
          this.audioQueue = [];
          this.isPlayingQueue = false;
          this.nextStartTime = 0;

          // Reset audio context timing
          if (this.audioContext) {
            this.nextStartTime = this.audioContext.currentTime;
          }

          this.socket.emit("interrupt");
          this.updateStatus("Interrupted. Ready for next input.");
        }

        sendTextMessage() {
          const message = this.textInput.value.trim();
          if (message && this.isConnected) {
            this.displayMessage("user", message);
            this.socket.emit("text-message", message);
            this.textInput.value = "";
            this.updateStatus("Processing...");
          }
        }

        displayMessage(sender, message) {
          const messageDiv = document.createElement("div");
          messageDiv.className = `message ${sender}`;

          if (sender === "assistant") {
            messageDiv.innerHTML = `<strong>FAZZRIE:</strong> <span class="message-content">${message}</span>`;
          } else if (sender === "transcript") {
            messageDiv.innerHTML = message;
          } else {
            messageDiv.innerHTML = `<strong>You:</strong> ${message}`;
          }

          this.chatContainer.appendChild(messageDiv);
          this.chatContainer.scrollTop = this.chatContainer.scrollHeight;

          return messageDiv;
        }

        appendToLastMessage(sender, text) {
          const messages = this.chatContainer.querySelectorAll(
            `.message.${sender}`
          );
          let lastMessage = messages[messages.length - 1];

          if (!lastMessage) {
            lastMessage = this.displayMessage(sender, "");
          }

          const content = lastMessage.querySelector(".message-content");
          if (content) {
            content.textContent += text;
          } else {
            lastMessage.innerHTML += text;
          }

          this.chatContainer.scrollTop = this.chatContainer.scrollHeight;
        }

        async playAudioDelta(audioData) {
          try {
            // Create audio from base64 PCM16 data
            const audioBuffer = this.base64ToArrayBuffer(audioData);

            // Initialize AudioContext with consistent sample rate if not exists
            if (!this.audioContext) {
              this.audioContext = new AudioContext({ sampleRate: 24000 });
              this.nextStartTime = this.audioContext.currentTime;
              console.log(
                `üéµ AudioContext initialized at ${this.audioContext.sampleRate}Hz`
              );
            }

            // Ensure AudioContext is running
            if (this.audioContext.state === "suspended") {
              await this.audioContext.resume();
            }

            // For PCM16 data, we need to create an AudioBuffer manually
            const pcm16Array = new Int16Array(audioBuffer);

            // Skip empty or very small audio chunks that can cause noise
            if (pcm16Array.length < 32) {
              console.log(
                "üîá Skipping very small audio chunk to prevent noise"
              );
              return;
            }

            const audioBufferObj = this.audioContext.createBuffer(
              1,
              pcm16Array.length,
              24000 // Match the PCM16 sample rate exactly
            );
            const channelData = audioBufferObj.getChannelData(0);

            // Convert PCM16 to float32 with better normalization
            for (let i = 0; i < pcm16Array.length; i++) {
              // Normalize to [-1, 1] range with proper scaling
              channelData[i] = pcm16Array[i] / 32768.0;
            }

            // Add to queue with better timing info
            this.audioQueue.push({
              buffer: audioBufferObj,
              timestamp: Date.now(),
              duration: audioBufferObj.duration,
            });

            // Start processing queue if not already running
            if (!this.isPlayingQueue) {
              this.processAudioQueue();
            }
          } catch (error) {
            console.error("Error preparing audio delta:", error);
          }
        }

        processAudioQueue() {
          if (this.audioQueue.length === 0 || this.isPlayingQueue) {
            return;
          }

          this.isPlayingQueue = true;

          const playNextChunk = () => {
            if (this.audioQueue.length === 0) {
              this.isPlayingQueue = false;
              return;
            }

            const audioChunk = this.audioQueue.shift();
            const source = this.audioContext.createBufferSource();
            source.buffer = audioChunk.buffer;

            // Apply speech rate control for Realtime API audio
            const effectiveRate = this.speechRate || 1.0;
            source.playbackRate.value = effectiveRate;

            // Create a gain node for smooth volume control
            const gainNode = this.audioContext.createGain();
            source.connect(gainNode);
            gainNode.connect(this.audioContext.destination);

            // Calculate when to start this chunk to maintain perfect continuity
            const now = this.audioContext.currentTime;
            let startTime;

            if (this.nextStartTime <= now) {
              // If we're behind schedule, start immediately but don't accumulate delay
              startTime = now;
              this.nextStartTime = now;
            } else {
              // Start at the scheduled time for perfect continuity
              startTime = this.nextStartTime;
            }

            // Calculate duration with playback rate applied
            const chunkDuration = audioChunk.buffer.duration / effectiveRate;
            this.nextStartTime = startTime + chunkDuration;

            // Add slight fade in/out to prevent clicks between chunks
            const fadeTime = Math.min(0.002, chunkDuration / 4); // 2ms or 1/4 of chunk duration
            gainNode.gain.setValueAtTime(0, startTime);
            gainNode.gain.linearRampToValueAtTime(1, startTime + fadeTime);
            gainNode.gain.setValueAtTime(
              1,
              startTime + chunkDuration - fadeTime
            );
            gainNode.gain.linearRampToValueAtTime(0, startTime + chunkDuration);

            source.onended = () => {
              // Immediately play next chunk without delay for seamless audio
              if (this.audioQueue.length > 0) {
                playNextChunk();
              } else {
                this.isPlayingQueue = false;
              }
            };

            // Debug logging (reduce frequency to avoid spam)
            // if (Math.random() < 0.1) {
            //   // Only log ~10% of chunks
            //   console.log(
            //     `üéµ Playing audio chunk: ${effectiveRate}x speed, ${chunkDuration.toFixed(
            //       3
            //     )}s, queue: ${this.audioQueue.length}`
            //   );
            // }

            source.start(startTime);
            this.currentAudio = source;
          };

          playNextChunk();
        }

        clearAudioQueue() {
          console.log("üßπ Clearing audio queue and stopping playback");

          // Stop current audio gracefully
          if (this.currentAudio) {
            try {
              this.currentAudio.stop();
            } catch (e) {
              // Audio source might already be stopped
              console.log("Audio source already stopped");
            }
            this.currentAudio = null;
          }

          // Clear queue and reset timing
          this.audioQueue = [];
          this.isPlayingQueue = false;

          if (this.audioContext) {
            this.nextStartTime = this.audioContext.currentTime;
          }
        }

        async playServerAudio(audioResponse, text) {
          try {
            console.log(
              "üéµ Playing server-generated TTS audio:",
              audioResponse.format
            );

            if (audioResponse.format === "mp3" && audioResponse.data) {
              // Handle MP3 audio from Google Cloud TTS
              const audioBlob = this.base64ToBlob(
                audioResponse.data,
                "audio/mp3"
              );
              const audioUrl = URL.createObjectURL(audioBlob);
              const audio = new Audio(audioUrl);

              // Apply speech rate control
              const effectiveRate = this.speechRate || 1.0;
              audio.playbackRate = effectiveRate;

              audio.onplay = () => {
                this.updateStatus("üîä AI is speaking (server TTS)...");
              };

              audio.onended = () => {
                this.updateStatus("Response complete. Ready for next input.");
                URL.revokeObjectURL(audioUrl);
              };

              audio.onerror = (error) => {
                console.error("Audio playback error:", error);
                // Fallback to browser TTS
                this.speakText(text);
              };

              await audio.play();
            } else if (audioResponse.format === "system") {
              // System TTS (macOS 'say' command) - audio is already played
              this.updateStatus("üîä AI spoke via system TTS");
              setTimeout(() => {
                this.updateStatus("Response complete. Ready for next input.");
              }, 2000);
            } else {
              // Fallback to browser TTS for other formats
              console.log("Falling back to browser TTS");
              this.speakText(text);
            }
          } catch (error) {
            console.error("Error playing server audio:", error);
            // Fallback to browser TTS
            this.speakText(text);
          }
        }

        base64ToBlob(base64Data, contentType) {
          const byteCharacters = atob(base64Data);
          const byteNumbers = new Array(byteCharacters.length);
          for (let i = 0; i < byteCharacters.length; i++) {
            byteNumbers[i] = byteCharacters.charCodeAt(i);
          }
          const byteArray = new Uint8Array(byteNumbers);
          return new Blob([byteArray], { type: contentType });
        }

        base64ToArrayBuffer(base64) {
          const binaryString = atob(base64);
          const bytes = new Uint8Array(binaryString.length);
          for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
          }
          return bytes.buffer;
        }

        updateConnectionStatus(type, message) {
          this.connectionStatus.className = `status-badge ${type}`;
          this.connectionStatus.textContent = message;
        }

        updateStatus(message) {
          this.status.textContent = message;
        }

        speakText(text) {
          // Use Web Speech API for text-to-speech in fallback mode
          if ("speechSynthesis" in window) {
            // Cancel any ongoing speech
            window.speechSynthesis.cancel();

            const utterance = new SpeechSynthesisUtterance(text);

            // Try to match the selected voice or use a default
            const voices = window.speechSynthesis.getVoices();
            const selectedVoice = 'onyx';

            // Map OpenAI voice names to similar browser voices (Indonesian)
            const voiceMap = {
              alloy: "Google Bahasa Indonesia",
              echo: "Indonesian",
              fable: "Bahasa Indonesia",
              onyx: "Indonesian Male",
              nova: "Indonesian Female",
              shimmer: "Bahasa Indonesia Female",
            };

            const preferredVoiceName = voiceMap[selectedVoice] || selectedVoice;
            const matchedVoice = voices.find(
              (voice) =>
                voice.name.includes(preferredVoiceName) ||
                voice.name.includes("Indonesian") ||
                voice.name.includes("Bahasa") ||
                voice.lang === "id-ID" ||
                voice.lang === "id"
            );

            if (matchedVoice) {
              utterance.voice = matchedVoice;
            }

            // Use dynamic speech settings from server
            utterance.rate = this.speechRate || 1.0; // Fallback to 1.0 if not set
            utterance.pitch = this.speechPitch || 1.0; // Fallback to 1.0 if not set
            utterance.volume = 1.0;

            utterance.onstart = () => {
              this.updateStatus("üîä AI is speaking...");
            };

            utterance.onend = () => {
              this.updateStatus("Ready for next input.");
            };

            utterance.onerror = (event) => {
              console.error("Speech synthesis error:", event);
              this.updateStatus("Ready for next input.");
            };

            window.speechSynthesis.speak(utterance);
          } else {
            console.warn("Speech synthesis not supported in this browser");
            this.updateStatus("Ready for next input.");
          }
        }

        showConfirmationButtons(message, confirmationData) {
          const confirmationButtons = document.getElementById(
            "confirmationButtons"
          );
          const confirmationMessage = document.getElementById(
            "confirmationMessage"
          );

          confirmationMessage.textContent = message;
          confirmationButtons.style.display = "block";

          // Store confirmation data for later use
          this.pendingConfirmationData = confirmationData;
        }

        hideConfirmationButtons() {
          const confirmationButtons = document.getElementById(
            "confirmationButtons"
          );
          confirmationButtons.style.display = "none";
          this.pendingConfirmationData = null;
        }

        handleConfirmation(confirmed) {
          console.log("Pulsa confirmation:", confirmed ? "YES" : "NO");

          // Send confirmation to server
          this.socket.emit("pulsa-confirmation", {
            confirmed: confirmed,
            data: this.pendingConfirmationData,
          });

          // Hide confirmation buttons
          this.hideConfirmationButtons();

          // Update status
          this.updateStatus(
            confirmed ? "Processing purchase..." : "Purchase cancelled"
          );
        }

        loadSpeechSynthesisVoices() {
          // Load browser voices when in fallback mode
          if ("speechSynthesis" in window) {
            const loadVoices = () => {
              const voices = window.speechSynthesis.getVoices();
              if (voices.length > 0 && this.mode === "fallback") {
                console.log(
                  "Available speech synthesis voices:",
                  voices.map((v) => v.name)
                );
                // Voices are available, but we'll keep using the existing OpenAI voice names
                // for consistency, and map them in speakText()
              }
            };

            // Load voices immediately if available
            loadVoices();

            // Also load when voices change (some browsers load them asynchronously)
            if (window.speechSynthesis.addEventListener) {
              window.speechSynthesis.addEventListener(
                "voiceschanged",
                loadVoices
              );
            }
          }
        }

        enableControls() {
          this.voiceButton.disabled = false;
          // this.interruptButton.disabled = false;
          // this.voiceSelect.disabled = false;
          this.textInput.disabled = false;
          this.sendButton.disabled = false;
        }

        disableControls() {
          this.voiceButton.disabled = true;
          // this.interruptButton.disabled = true;
          // this.voiceSelect.disabled = true;
          this.textInput.disabled = true;
          this.sendButton.disabled = true;
        }

        initializeSpeechRecognition() {
          // Initialize Web Speech API for fallback mode
          if ("webkitSpeechRecognition" in window) {
            this.speechRecognition = new webkitSpeechRecognition();
          } else if ("SpeechRecognition" in window) {
            this.speechRecognition = new SpeechRecognition();
          }

          if (this.speechRecognition) {
            this.speechRecognition.continuous = false;
            this.speechRecognition.interimResults = false;
            this.speechRecognition.lang = "en-US";

            this.speechRecognition.onstart = () => {
              console.log("üé§ Browser speech recognition started");
              this.updateStatus(
                "üé§ Listening with browser speech recognition..."
              );
            };

            this.speechRecognition.onresult = (event) => {
              const transcript = event.results[0][0].transcript;
              console.log("üìù Speech recognized:", transcript);
              this.displayMessage("user", `üé§ "${transcript}"`);
              this.socket.emit("text-message", transcript);
              this.updateStatus("Processing...");
            };

            this.speechRecognition.onerror = (event) => {
              console.error("Speech recognition error:", event.error);
              this.updateStatus("Speech recognition error: " + event.error);
            };

            this.speechRecognition.onend = () => {
              console.log("ü§ê Browser speech recognition ended");
              this.voiceButton.textContent = "üó£Ô∏è Bicara";
              this.voiceButton.classList.remove("listening");
              this.isRecording = false;
            };
          }

          // Initialize speech synthesis voices
          this.loadSpeechSynthesisVoices();
        }
      }

      // Initialize the client when the page loads
      window.addEventListener("DOMContentLoaded", () => {
        new RealtimeVoiceClient();
      });
    </script>
</body>

</html>